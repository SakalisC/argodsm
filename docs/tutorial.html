<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Tutorial - ArgoDSM</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" href="style.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<nav>
<ul>
	<li><a href="/argodsm/">Home</a></li>
	<li><a href="/argodsm/documentation.html">Documentation</a></li>
	<li><a href="/argodsm/tutorial.html">Tutorial</a></li>
	<li><a href="/argodsm/download.html">Download</a></li>
	<li><a href="/argodsm/about.html">About</a></li>
</ul>
</nav>
<h1 id="tutorial">Tutorial</h1>
<p>This is a set of small tutorials on how to convert pthreads applications to run on ArgoDSM. We will start with a very simple example, and then move to real pthreads applications.</p>
<p>We assume that you have already <a href="/argodsm/">compiled the ArgoDSM libraries</a> and that you have installed them in a user local directory. We will also assume knowledge of the Pthreads library and programming model, as well as very basic knowledge of MPI. If you are not familiar with either, you might find this tutorial confusing.</p>
<h2 id="the-simple-example">The Simple Example</h2>
<p>This example is meant as an introduction to ArgoDSM and its differences with non-distributed pthreads applications. It is written in C++. For brevity, we assume that the input data is evenly divisible by the number of threads and that the number of threads is evenly divisible by the number of nodes. We also omit error checking code.</p>
<h3 id="just-pthreads">Just Pthreads</h3>
<div class="sourceCode" include="pthreads_example.cpp"><table class="sourceCode Cpp numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
</pre></td><td class="sourceCode"><pre><code class="sourceCode cpp"><span class="ot">#include &lt;cassert&gt;</span>
<span class="ot">#include &lt;limits&gt;</span>
<span class="ot">#include &lt;iostream&gt;</span>
<span class="ot">#include &lt;vector&gt;</span>

<span class="ot">#include &lt;pthread.h&gt;</span>

<span class="kw">struct</span> thread_args {
	<span class="dt">int</span> data_begin;
	<span class="dt">int</span> data_end;
};

<span class="dt">int</span> *data;
<span class="dt">int</span> max = std::numeric_limits&lt;<span class="dt">int</span>&gt;::min();

pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

<span class="dt">void</span>* parmax(<span class="dt">void</span>* argptr) {
	<span class="co">// Get the arguments</span>
	thread_args* args = <span class="kw">static_cast</span>&lt;thread_args*&gt;(argptr);

	<span class="co">// Let&#39;s declutter the code a bit, while also avoiding unnecessary global</span>
	<span class="co">// memory accesses</span>
	<span class="dt">int</span> data_begin = args-&gt;data_begin;
	<span class="dt">int</span> data_end = args-&gt;data_end;

	<span class="co">// Find the local maximum</span>
	<span class="dt">int</span> local_max = std::numeric_limits&lt;<span class="dt">int</span>&gt;::min();
	<span class="kw">for</span> (<span class="dt">int</span> i = data_begin; i &lt; data_end; ++i) {
		<span class="kw">if</span> (data[i] &gt; local_max) {
			local_max = data[i];
		}
	}

	<span class="co">// Change the global maximum (if necessary)</span>
	pthread_mutex_lock(&amp;lock);
	<span class="kw">if</span> (local_max &gt; max)
		max = local_max;
	pthread_mutex_unlock(&amp;lock);

	<span class="kw">return</span> <span class="kw">nullptr</span>;
}

<span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span>* argv[]) {
	<span class="dt">int</span> data_length = <span class="dv">160000</span>;
	<span class="dt">int</span> num_threads = <span class="dv">16</span>;

	<span class="co">// Allocate the array</span>
	data = <span class="kw">new</span> <span class="dt">int</span>[data_length];

	<span class="co">// Initialize the input data</span>
	<span class="kw">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; data_length; ++i)
		data[i] = i * <span class="dv">11</span> + <span class="dv">3</span>;

	<span class="co">// Start the threads</span>
	<span class="dt">int</span> chunk = data_length / num_threads;
	std::vector&lt;pthread_t&gt; threads(num_threads);
	std::vector&lt;thread_args&gt; args(num_threads);
	<span class="kw">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; num_threads; ++i) {
		args[i].data_begin = i * chunk;
		args[i].data_end = args[i].data_begin + chunk;
		pthread_create(&amp;threads[i], <span class="kw">nullptr</span>, parmax, &amp;args[i]);
	}
	<span class="co">// Join the threads</span>
	<span class="kw">for</span> (<span class="kw">auto</span>&amp; t : threads)
		pthread_join(t, <span class="kw">nullptr</span>);

	<span class="kw">delete</span>[] data;
	<span class="co">// Print the result</span>
	std::cout &lt;&lt; <span class="st">&quot;Max found to be &quot;</span> &lt;&lt; max &lt;&lt; std::endl;
	assert(max == ((data_length - <span class="dv">1</span>) * <span class="dv">11</span> + <span class="dv">3</span>));
}</code></pre></td></tr></table></div>
<p>The example finds the biggest number in an integer array. The astute reader might realize that the biggest number is actually always the same and it can be determined by a very simple calculation, but this is after all just an example. The array is initialized by the main thread and then the worker threads are started. Each worker threads receives as an argument a part of the array, in the form of [first, last) index. While the worker threads are working, the main thread is waiting for them to finish. After they are done, the main thread accesses the <code>max</code> variable, prints it, and makes sure the result is correct.</p>
<p>The worker threads work only on their local part of the array. After they find the local maximum, then they check and update the global maximum (<code>max</code>) variable. Since multiple threads might access this variable at the same time, it is protected by locks.</p>
<h3 id="scaling-it-up-with-argodsm">Scaling it up with ArgoDSM</h3>
<p>The first step is adding the ArgoDSM initialization and finalization function. Specifically, <code>argo::init</code> needs to be run in <code>main</code> before any other functions are called, and <code>argo::finalize</code> should be the last ArgoDSM function called before exiting <code>main</code>. In the current version of ArgoDSM, <code>argo::init</code> has one required argument which indicates the total amount of memory ArgoDSM should allocate. This will be deprecated in future versions.</p>
<p>In addition to adding the ArgoDSM initialization and finalization functions, there are three main tasks that need to be done to convert a pthreads application to ArgoDSM.</p>
<ol type="1">
<li>Remove data races.</li>
<li>Allocate shared (ArgoDSM) data using the ArgoDSM allocators.</li>
<li>Replace any Pthreads synchronization primitives with corresponsing primitives provided by ArgoDSM.</li>
<li>Take care of the changes introduced by the new multiple process model.</li>
</ol>
<p>Removing data races (1) is unnecessary in this case, since the pthreads application is standard (both POSIX and C++) compliant, so it is already data race free.</p>
<p>In order to allocate all the shared data in the global memory (2), we need to make two changes. First, we need to switch any calls to <code>new</code> with calls to the ArgoDSM allocators. Specifically, we need to replace <code>new int[data_length]</code> with <code>argo::conew_array&lt;int&gt;(data_length)</code>. This allocation function <code>argo::conew_array</code> is run on all the nodes, returning the same pointer to all of them, thus initializing the <code>data</code> variable in all of them. So this:</p>
<div class="sourceCode"><pre class="sourceCode Cpp"><code class="sourceCode cpp">data = <span class="kw">new</span> <span class="dt">int</span>[data_length];</code></pre></div>
<p>needs to become this:</p>
<div class="sourceCode"><pre class="sourceCode Cpp"><code class="sourceCode cpp">data = argo::conew_array&lt;<span class="dt">int</span>&gt;(data_length);</code></pre></div>
<p>Then, we need to move the <code>max</code> variable on the shared memory. ArgoDSM currently does not support mapping statically allocated variables into the global memory, so we will convert <code>max</code> into a pointer and allocate memory for it on the global memory. We will use the <code>argo::conew_&lt;int&gt;</code> function for this, giving as an initialization argument the same argument as we have in the pthreads example. This means changing this:</p>
<div class="sourceCode"><pre class="sourceCode Cpp"><code class="sourceCode cpp"><span class="dt">int</span> max = std::numeric_limits&lt;<span class="dt">int</span>&gt;::min();</code></pre></div>
<p>to this:</p>
<div class="sourceCode"><pre class="sourceCode Cpp"><code class="sourceCode cpp"><span class="dt">int</span> *max;
... <span class="co">// Somewhere inside main</span>
max = argo::conew_&lt;<span class="dt">int</span>&gt;(std::numeric_limits&lt;<span class="dt">int</span>&gt;::min());</code></pre></div>
<p>Note that the ArgoDSM functions can only be used after <code>argo::init</code> has been called, so we need to move the allocation and initialization of <code>max</code> inside the <code>main</code> function.</p>
<p>In addition to the <code>argo::conew_</code> family of functions, which needs to be called by <strong>all</strong> the nodes at the same time, there is also the <code>argo::new_</code> family which behaves like normal <code>new</code> but allocates globally shared memory.</p>
<p>We can now move on to the synchronization primitives(3). For this example we will use the <code>argo::globallock::global_tas_lock</code> available in ArgoDSM, but the <code>argo::simple_lock</code>, which will be made available soon, should be used instead. The <code>global_tas_lock</code> requires as an argument a boolean variable to spin on, which of course has to be allocated on the global memory.</p>
<div class="sourceCode"><pre class="sourceCode Cpp"><code class="sourceCode cpp">lock_flag = argo::conew_&lt;<span class="dt">bool</span>&gt;(<span class="kw">false</span>);
lock = <span class="kw">new</span> argo::globallock::global_tas_lock(lock_flag);</code></pre></div>
<p>Finally, we need to take into consideration the fact that ArgoDSM runs multiple processes (which also means multiple threads) from the beginning of the program execution (4). Essentially, each node has one process which has one main thread. For each of those processes, we want to initialize the <em>non-shared</em> global data individually (this is why we are using <code>argo::conew_</code>) but at the same time we want <strong>only one</strong> node to initialize the <em>shared</em> global data. If multiple nodes where to initialize the same data at the same time, we would have a data race. Usually, the simplest way to do that is to have <code>Node 0</code> initialize all the data and then synchronize with all the other nodes. We achieve that by using an <code>if</code> statement in conjunction with <code>argo::barrier</code>. The same goes for any work done by the application after the threads have finished; we want to make sure that work that needs to be done by only one thread will be done by only one node.</p>
<div class="sourceCode"><pre class="sourceCode Cpp"><code class="sourceCode cpp"><span class="kw">if</span> (argo::node_id() == <span class="dv">0</span>) {
    <span class="kw">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; data_length; ++i)
        data[i] = i * <span class="dv">11</span> + <span class="dv">3</span>;
}
argo::barrier();</code></pre></div>
<p>We also need to remember that each node starts its own threads, so we should either change how many threads each node starts or how we partition the shared data. In this example we decided to simple evenly split the number of threads between the available nodes.</p>
<div class="sourceCode"><pre class="sourceCode Cpp"><code class="sourceCode cpp">local_num_threads = num_threads / argo::number_of_nodes();
...
<span class="dt">int</span> chunk = data_length / num_threads;
std::vector&lt;pthread_t&gt; threads(local_num_threads);
std::vector&lt;thread_args&gt; args(local_num_threads);
<span class="kw">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; local_num_threads; ++i) {
    <span class="dt">int</span> global_tid = (argo::node_id() * local_num_threads) + i;
    args[i].data_begin = global_tid * chunk;
    args[i].data_end = args[i].data_begin + chunk;
    pthread_create(&amp;threads[i], <span class="kw">nullptr</span>, parmax, &amp;args[i]);
}</code></pre></div>
<p>The final result of all the changes is this:</p>
<div class="sourceCode" include="argo_example.cpp"><table class="sourceCode Cpp numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
</pre></td><td class="sourceCode"><pre><code class="sourceCode cpp"><span class="ot">#include &lt;cassert&gt;</span>
<span class="ot">#include &lt;limits&gt;</span>
<span class="ot">#include &lt;iostream&gt;</span>
<span class="ot">#include &lt;vector&gt;</span>

<span class="ot">#include &lt;pthread.h&gt;</span>

<span class="ot">#include &quot;argo/argo.hpp&quot;</span>

<span class="kw">struct</span> thread_args {
	<span class="dt">int</span> data_begin;
	<span class="dt">int</span> data_end;
};

<span class="dt">int</span> *data;
<span class="dt">int</span> *max;

<span class="dt">bool</span> *lock_flag;
argo::globallock::global_tas_lock *lock;

<span class="dt">void</span>* parmax(<span class="dt">void</span>* argptr) {
	<span class="co">// Get the arguments</span>
	thread_args* args = <span class="kw">static_cast</span>&lt;thread_args*&gt;(argptr);

	<span class="co">// Let&#39;s declutter the code a bit, while also avoiding unnecessary global</span>
	<span class="co">// memory accesses</span>
	<span class="dt">int</span> data_begin = args-&gt;data_begin;
	<span class="dt">int</span> data_end = args-&gt;data_end;

	<span class="co">// Find the local maximum</span>
	<span class="dt">int</span> local_max = std::numeric_limits&lt;<span class="dt">int</span>&gt;::min();
	<span class="kw">for</span> (<span class="dt">int</span> i = data_begin; i &lt; data_end; ++i) {
		<span class="kw">if</span> (data[i] &gt; local_max) {
			local_max = data[i];
		}
	}

	<span class="co">// Change the global maximum (if necessary)</span>
	lock-&gt;lock();
	<span class="kw">if</span> (local_max &gt; *max)
		*max = local_max;
	lock-&gt;unlock();

	<span class="kw">return</span> <span class="kw">nullptr</span>;
}

<span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span>* argv[]) {
	<span class="dt">int</span> data_length = <span class="dv">160000</span>;
	<span class="dt">int</span> num_threads = <span class="dv">16</span>;
	<span class="dt">int</span> local_num_threads;

	<span class="co">// We totally need 10GB for this application</span>
	argo::init(<span class="dv">10</span>*<span class="dv">1024</span>*<span class="dv">1024</span>*<span class="dv">1024UL</span>);

	local_num_threads = num_threads / argo::number_of_nodes();

	<span class="co">// Initialize the lock</span>
	lock_flag = argo::conew_&lt;<span class="dt">bool</span>&gt;(<span class="kw">false</span>);
	lock = <span class="kw">new</span> argo::globallock::global_tas_lock(lock_flag);
	<span class="co">// Allocate the array</span>
	data = argo::conew_array&lt;<span class="dt">int</span>&gt;(data_length);
	max = argo::conew_&lt;<span class="dt">int</span>&gt;(std::numeric_limits&lt;<span class="dt">int</span>&gt;::min());

	<span class="co">// Initialize the input data</span>
	<span class="kw">if</span> (argo::node_id() == <span class="dv">0</span>) {
		<span class="kw">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; data_length; ++i)
			data[i] = i * <span class="dv">11</span> + <span class="dv">3</span>;
	}
	
	<span class="co">// Make sure initialization is done and distribute the changes</span>
	argo::barrier();

	<span class="co">// Start the threads</span>
	<span class="dt">int</span> chunk = data_length / num_threads;
	std::vector&lt;pthread_t&gt; threads(local_num_threads);
	std::vector&lt;thread_args&gt; args(local_num_threads);
	<span class="kw">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; local_num_threads; ++i) {
		<span class="dt">int</span> global_tid = (argo::node_id() * local_num_threads) + i;
		args[i].data_begin = global_tid * chunk;
		args[i].data_end = args[i].data_begin + chunk;
		pthread_create(&amp;threads[i], <span class="kw">nullptr</span>, parmax, &amp;args[i]);
	}
	<span class="co">// Join the threads</span>
	<span class="kw">for</span> (<span class="kw">auto</span> &amp;t : threads)
		pthread_join(t, <span class="kw">nullptr</span>);

	<span class="co">// Make sure everyone is done and get the changes</span>
	argo::barrier();

	argo::codelete_array(data);
        <span class="kw">delete</span> lock;
	argo::codelete_(lock_flag);
	<span class="co">// Print the result</span>
	<span class="kw">if</span> (argo::node_id() == <span class="dv">0</span>)
		std::cout &lt;&lt; <span class="st">&quot;Max found to be &quot;</span> &lt;&lt; *max &lt;&lt; std::endl;
	assert(*max == ((data_length - <span class="dv">1</span>) * <span class="dv">11</span> + <span class="dv">3</span>));

	argo::finalize();
}</code></pre></td></tr></table></div>
<p>We can now compile the application. We assume that <code>${ARGO_INSTALL_DIRECTORY}</code> is where you installed ArgoDSM. If the ArgoDSM files are already in your <code>(LD_)LIBRARY_PATH</code> and include path, you can skip the <code>-L...</code> and <code>-I...</code> switches. If you have no idea what we are talking about, you should ask your system administrator.</p>
<div class="sourceCode"><pre class="sourceCode Bash"><code class="sourceCode bash"><span class="kw">mpic++</span> -O3 -std=c++11 -o argo_example   \
    -L<span class="ot">${ARGO_INSTALL_DIRECTORY}</span>/lib     \
    -I<span class="ot">${ARGO_INSTALL_DIRECTORY}</span>/include \
    argo_example.cpp -largo -largobackend-mpi</code></pre></div>
<p>This should produce an executable file that can be run with MPI. For instructions on how to run MPI applications you should contact your local support office. A generic example with OpenMPI on a cluster utilizing Slurm might look like this:</p>
<div class="sourceCode"><pre class="sourceCode Bash"><code class="sourceCode bash"><span class="kw">mpirun</span> --map-by ppr:1:node                                               \
    --mca mpi_leave_pinned 1 --mca btl openib,self,sm -n <span class="ot">${SLURM_NNODES}</span> \
    ./argo_example</code></pre></div>
</body>
</html>
